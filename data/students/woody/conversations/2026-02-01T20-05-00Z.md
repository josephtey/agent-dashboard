# Conversation with Woody

**Date:** 2026-02-01T20:05:00Z
**Duration:** 10 minutes
**Participants:** PI and Woody

## Summary

Explored beyond-agents codebase and discussed agentic search as first major functionality. Analyzed current async architecture, tool registry pattern, and README roadmap. Decided to prioritize agentic search despite being Phase 4c because it provides immediate value and forces solving parallel execution early. Proposed three-phase implementation approach.

## Key Topics

- Agentic search architecture
- Beyond-agents codebase structure
- Parallel tool execution
- Full-text search vs embeddings
- Tool registry pattern
- Async architecture foundations
- Implementation phasing strategy

## Transcript

**PI:** Hello, chat to Woody

**Woody:** Hey! Woody here. I've been diving into the beyond-agents codebase - this agent harness architecture is fascinating stuff. I've got two tasks queued up for the repo: implementing parallel tool calling (Task #5) and converting the CLI to a full-stack Next.js app (Task #6).

I'm particularly interested in the parallel tool calling challenge - thinking through how to orchestrate multiple tool invocations concurrently without race conditions or dependency issues. There's some elegant design patterns to work through there.

What's on your mind? Want to discuss the architecture, talk through one of these tasks, or explore something else in the agent infrastructure space?

**PI:** It may be helpful for you to read the beyond-agents repo and see what is worth working on. I do think one good first functionality for the harness could be agentic search. Thoughts?

**Woody:** Good idea - let me dig into the repo and see what we're working with. I should understand the current architecture before we decide on priorities.

[Reads beyond-agents codebase files: README.md, src/agent.py, src/tools/base.py, src/tools/implementations/read_file.py]

Okay, I see where we are. This is really interesting - we've got a solid foundation here. Let me think through this...

**Current state:**
- Clean async architecture with Anthropic API integration
- Tool registry pattern that's extensible
- Basic tools: `read_file` and `web_search` (via MCP)
- The roadmap has agentic search planned for "Phase 4c"

**Your intuition is spot on.** Looking at the roadmap, there's a bunch of stuff in phases 1-3 (more tools, BFCL eval, parallel execution, batch tools). But honestly? Agentic search might be the *perfect* first real functionality to build, even if it's "out of order."

Here's why I'm thinking this:

1. **Immediate usefulness**: Right now the agent can read individual files if you give it a path. But navigating a real codebase? That's where it gets valuable. Agentic search makes the harness actually useful for exploring code.

2. **Forces us to solve the important problems early**:
   - **Parallel tool execution** (Phase 3) is listed as future work, but it's critical for fast agentic search. The referenced blog post shows 4x latency reduction with parallel search. We'd need to tackle this now.
   - The architecture is already async, so adding parallel tool execution is a natural extension

3. **Architecture implications**:
   - We'd need core search tools: `view_file`, `view_directory`, `grep_search`, and crucially `report_back`
   - Full-text search index (Tantivy in Rust, or Python equivalent)
   - The "search → filter → report" workflow keeps the main conversation clean

4. **Lean into our strengths**: The async foundation we have is perfect for this. We just need to modify the tool execution loop in `agent.py` to handle parallel calls instead of sequential.

**Trade-offs:**
- We'd be skipping some of the basic tools (write_file, list_directory, run_bash). But honestly, those are straightforward to add later.
- We'd be tackling parallel execution earlier than planned. That's more complex, but it's worth it if agentic search is the goal.

**My recommendation:** Yes, let's do agentic search as the first major functionality. But let's be smart about the scope:

**Phase 1 - Basic Search Tools (get something working):**
- `view_file` - read a specific file
- `list_directory` - see what's in a folder
- `grep_search` - keyword search across files
- Sequential tool execution first (we can optimize to parallel later)

**Phase 2 - Parallel Execution (make it fast):**
- Modify agent loop to execute tools in parallel when possible
- This is where we get the 4x speed improvement

**Phase 3 - Search Index (make it scale):**
- Add full-text search index (Tantivy or Python equivalent)
- Offline document augmentation

What do you think? Should we go this route? And if so, should I focus on getting Phase 1 working first, or do you want to tackle parallel execution from the start?

**PI:** Yeah cool; save all this context, especially what you learned in the readme; and I'll loop back to you tomorrow about what to build.

## Action Items

- Confirm agentic search approach tomorrow
- Decide whether to start with basic tools or tackle parallel execution immediately
- Begin detailed implementation planning for Phase 1 (basic search tools)
- Research Python full-text search libraries (alternative to Tantivy)

## New Learnings

- Beyond-agents has production-ready async architecture (AsyncAnthropic client, async tools, async MCP client)
- Tool execution loop in agent.py:130-161 is sequential - needs modification for parallel execution
- Agentic search provides 4x latency reduction via parallel execution (20→5 turns)
- Search → Filter → Report workflow keeps context clean and prevents pollution
- Full-text search preferred over embeddings for predictable, interpretable results
- README already has comprehensive agentic search research documented in Phase 4c
- Current tools: read_file (uses asyncio.to_thread) and web_search (via MCP)
- Tool registry pattern makes adding new tools straightforward

## Decisions Made

1. **Prioritize agentic search as first major functionality** - Provides immediate value for codebase exploration and forces solving important architectural problems (parallel execution) early

2. **Three-phase implementation approach** - Start with basic search tools using sequential execution, then add parallel execution for speed, finally add full-text search index for scale

3. **Use full-text search over embeddings** - Better predictability and interpretability, avoids chunking issues and separate transformer infrastructure
